
"""CSC 5220 Project New Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DM0j0wGojeQSCBI-yMhyjq9tg7uPQV3i

This code uses a Recurrent Neural Network (RNN) to estimate vehicle fuel usage by approximating fuel flow with a BSFC-based formula using engine RPM and load data. The model is trained on normalized sequences from the POLIDriving dataset and predicts estimated fuel consumption over time.

 Visualization of predicted vs. estimated fuel usage demonstrates the RNN's ability to learn driving-related fuel trends without direct fuel sensor data.
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset, random_split

#Load and Preprocess Data
FILE_PATH = "20240208_120000_pre.csv"
SEQUENCE_LENGTH = 20
BATCH_SIZE = 32

df = pd.read_csv(FILE_PATH)

selected_features = [
    'speed', 'rpm', 'acceleration', 'throttle_position', 'engine_temperature',
    'engine_load_value', 'temperature', 'relative_humidity', 'precipitation', 'pressure'
]
df = df[selected_features].dropna()

#Estimate BSFC-based Fuel Rate
def estimate_fuel_rate(df, engine_displacement_l=2.4, max_torque_nm=200, bsfc_g_per_kwh=250):
    rpm = df['rpm']
    load = df['engine_load_value'] / 100
    torque = load * max_torque_nm
    power_kw = (torque * rpm * 2 * np.pi) / (60 * 1000)
    fuel_gh = power_kw * bsfc_g_per_kwh
    return fuel_gh / 745  # Convert to L/h (gasoline)

df['fuel_estimated_lph'] = estimate_fuel_rate(df)

# Normalize and Sequence
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[selected_features])

def create_sequences(data, seq_len):
    return np.array([data[i:i+seq_len] for i in range(len(data) - seq_len)])

sequence_data = create_sequences(scaled_data, SEQUENCE_LENGTH)
tensor_data = torch.tensor(sequence_data, dtype=torch.float32)

#Create Target Tensor (L/h)
target_data = torch.tensor(df['fuel_estimated_lph'].values[SEQUENCE_LENGTH:], dtype=torch.float32).unsqueeze(1)

#Dataset Split
dataset = TensorDataset(tensor_data, target_data)
train_size = int(0.8 * len(dataset))
train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)

#Define Model
class FuelMPGRNN(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

#Initialize and Train Model
input_size = tensor_data.shape[2]
model = FuelMPGRNN(input_size, hidden_size=64, num_layers=2, output_size=1)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

epochs = 100
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for X_batch, y_batch in train_loader:
        optimizer.zero_grad()
        pred = model(X_batch)
        loss = criterion(pred, y_batch)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(train_loader):.4f}")

#Evaluate and Plot
model.eval()
predictions, actuals = [], []

with torch.no_grad():
    for X_batch, y_batch in test_loader:
        out = model(X_batch)
        predictions.extend(out.squeeze().tolist())
        actuals.extend(y_batch.squeeze().tolist())

plt.figure(figsize=(10, 5))
plt.plot(predictions, label="Predicted Fuel Usage (L/h)")
plt.plot(actuals, label="Actual Fuel Usage (BSFC Estimate)")
plt.title("Predicted vs Actual Fuel Usage (L/h)")
plt.xlabel("Sample Index")
plt.ylabel("Fuel Usage (Liters per Hour)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()